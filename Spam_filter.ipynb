{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Spam Filter\n",
    "### -- by Chengrui Charlie Zheng\n",
    "## Introduction\n",
    "A spam filter is a filter in your email to filter spams, the mails you do not want to receive, out of hams, the legitimate emails you want. There are multiple ways of implementing a spam filter. I will use Naive Bayes Classifier and Bag-of-Words model to implement a Bayesian spam filter, the oldest kind of spam filter. This page will walk you through the process of implementation, training and testing.\n",
    "## Email and Text Cleaning\n",
    "When a email comes into your mailbox, there are a lot of features to determine whether the email is a spam or not. For a simple demonstration, I will only be analyzing the words in the body of a email, by calculating the probability of the word occuring in a spam. Here, I will first create a class of email as in the following code. The class consists of a constructor, which cleans the text, getters and setters for the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/charliez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charliez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "class Email():\n",
    "    \"\"\"This class simulates the emails\"\"\"\n",
    "    def __init__(self, id: int, file, score=0):\n",
    "        self.id = id  # id of each email\n",
    "        text = open(file,'rt').read()  # read the text of the file\n",
    "        words = word_tokenize(text) # split the text into words and strip all punctuation\n",
    "\n",
    "        # strip stop words and number, only remain the stems\n",
    "        en_stopwords = stopwords.words('english')\n",
    "        porter = PorterStemmer();\n",
    "        self.words = [porter.stem(w.lower()) for w in words if w.isalpha() and not w in en_stopwords]\n",
    "\n",
    "        self.score = score  # this is the score of the email's spamicity\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def get_words(self):\n",
    "        return self.words\n",
    "\n",
    "    def get_score(self):\n",
    "        return self.score\n",
    "\n",
    "    def set_score(self, new_score):\n",
    "        self.score = new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An email should have an \"ID\", a string list of \"words\", and a \"score\" indicating its spam score. The higher the spam score is, the more likely the mail is spam. When a new mail comes in, we will first set its score to be 0 by default. As for \"words\", we will do the  text cleaning by using 'nltk' module in python. First, it will read the text from the file, and tokenize the text to split the text into words. For example, if we have a sentence \"What do you mean by tokenizing?\". Aftering tokenizing the text, it will extract every tokens(a word, a number or a punctuation), and make the tokens into a string list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'do', 'you', 'mean', 'by', 'tokenizing', 'the', 'text', '?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What do you mean by tokenizing the text?\"\n",
    "tokenized = word_tokenize(text)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will filter the stop words out of the tokenized string list. Stop words are the commonly used but semantically insignificant words such as \"a\" and \"by\". Here are the new string list from our last example without stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'you', 'mean', 'tokenizing', 'text', '?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in tokenized:\n",
    "    if w in stopwords.words('english'):\n",
    "        tokenized.remove(w)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we only want to keep the stem of each words by making the letters lowercase, removing the inflection and some derivation; so that \"tokenized\", \"tokenizing\" and \"tokenize\" will be counted as the same word \"token\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'you', 'mean', 'token', 'text', '?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = [PorterStemmer().stem(w) for w in tokenized]\n",
    "stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we will remove the numbers and punctuations in the string list. After the text is clean, we can pass the emails to the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'you', 'mean', 'token', 'text']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in stems if w.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Naive Bayes Classifier\n",
    "This filter will be using a Naive Bayes Classifier to classify the comming emails. The more detailed application of  Bayes' Theorem will be explained below. Here is the class of filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter():\n",
    "    \"\"\"This class simulates the filter of the mailbox\"\"\"\n",
    "\n",
    "    def __init__(self, threshold: int):\n",
    "        \"\"\"this is the threshold of the spam score\"\"\"\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.inbox = []  # the inbox stores all hams\n",
    "        self.spams = []  # spams store all spams\n",
    "        self.spam_bow = {} # the bag of words of spams\n",
    "        self.ham_bow = {}  # the bag of words of hams\n",
    "\n",
    "\n",
    "    def word_spamicity(self, word: str) -> float:\n",
    "        \"\"\"Determines the spamicity of each word.\n",
    "\n",
    "        Args:\n",
    "            word (str): the word to be calculated\n",
    "\n",
    "        Returns:\n",
    "            psw (float): the spamicity of the word\n",
    "        \"\"\"\n",
    "        word_spam = 0  # the frequency of the word appeared in spams\n",
    "        word_ham = 0 # the frequency of the word appeared in hams\n",
    "\n",
    "        #checking the bags of words to set the frequency\n",
    "        if word in self.spam_bow.keys():\n",
    "            word_spam = self.spam_bow[word]\n",
    "        if word in self.ham_bow.keys():\n",
    "            word_ham = self.ham_bow[word]\n",
    "\n",
    "        #calculating the probability of a spam word\n",
    "        pws = float(word_spam/len(self.spams))\n",
    "        pwh = float(word_ham/len(self.inbox))\n",
    "        if (pws + pwh) == 0:\n",
    "            psw =0\n",
    "        else:\n",
    "            psw = float(pws/(pws+pwh))\n",
    "        return psw\n",
    "\n",
    "\n",
    "    def spam_score(self, mail: Email) -> int:\n",
    "        \"\"\"Calcuates the spam score of the email according to its words' spamicity\n",
    "\n",
    "        Args:\n",
    "            mail (Email): the mail to be calculated\n",
    "\n",
    "        Returns:\n",
    "            score (int): the spam score of the email according to its words' spamicity\n",
    "\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "\n",
    "        #getting the spamicity of each word\n",
    "        for w in mail.get_words():\n",
    "            spamicity = self.word_spamicity(w)\n",
    "            if spamicity >= 0.9:\n",
    "                score += 3\n",
    "            if spamicity >= 0.75 and spamicity < 0.9:\n",
    "                score += 2\n",
    "            if spamicity >= 0.5 and spamicity < 0.75:\n",
    "                score += 1\n",
    "        return score\n",
    "\n",
    "\n",
    "    def receive(self, mail: Email):\n",
    "        \"\"\"Receives a new email, calculates its spam score, update the bags of words, and sort the email\n",
    "\n",
    "        Args:\n",
    "            mail (Email): the new mail to be received\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # calculates the mail's spam score\n",
    "        score = self.spam_score(mail)\n",
    "        mail.set_score(score)\n",
    "\n",
    "        # sort the mail and update the bags of words\n",
    "        if score > self.threshold:\n",
    "            self.spams.append(mail)\n",
    "            print(mail.get_id() + ' is a spam. Its Spam score is ' + str(mail.get_score()))\n",
    "            self.add_words(self.spam_bow, mail.get_words())\n",
    "        else:\n",
    "            self.inbox.append(mail)\n",
    "            print(mail.get_id() + ' is not a spam. Its Spam score is ' + str(mail.get_score()))\n",
    "            self.add_words(self.ham_bow, mail.get_words())\n",
    "\n",
    "\n",
    "    def train(self, mail: Email, is_spam: bool):\n",
    "        \"\"\"Trains the filter\n",
    "\n",
    "        Args:\n",
    "            mail (Email): the training mail\n",
    "            is_spam (bool): whether mail is spam or not\n",
    "        \"\"\"\n",
    "\n",
    "        if is_spam:\n",
    "            self.spams.append(mail)\n",
    "            self.add_words(self.spam_bow, mail.get_words())\n",
    "        else:\n",
    "            self.inbox.append(mail)\n",
    "            self.add_words(self.ham_bow, mail.get_words())\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def add_words(bow: dict, words: list):\n",
    "        \"\"\"Adds words to the bag of words\n",
    "\n",
    "        Args:\n",
    "            bow (dict): the bag of words\n",
    "            words (list): the words to be added\n",
    "\n",
    "        \"\"\"\n",
    "        checked = set()  # the checked words\n",
    "\n",
    "        for w in words:\n",
    "            checked.add(w)\n",
    "            # update bag of words\n",
    "            if w not in bow.keys():\n",
    "                bow.update({w:1})\n",
    "            else:\n",
    "                recur = bow[w] + 1\n",
    "                bow.update({w:recur})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructor\n",
    "In the constructor, we can set a filter's threshold of the spam score. Hams with scores lower than the threshold will be passed into \"inbox\", an email list resembling the inbox in your mailbox. Spams with scores higher than the threshold will be passed into \"spams\", an email list of spams. There are also 2 bag-of-words, \"spam_bow\" for spams and \"ham_bow\" for hams. The bag-of-words model is a hashmap or a dictionary containing the words appeared in mails as keys, and the number of mails each word appeared as values. The example of the bag-of-words will be illustrated in the Training section.\n",
    "\n",
    "### Naive Bayes Foundation\n",
    "After the filter is constructed, it will calculate the spamicity, the probability that a message containing a given word is spam in \"word_spamicity\" function. The calculation process is based on Bayes' Theorem:\n",
    "$$\\Pr(S|W)=\\frac{\\Pr(W|S)\\Pr(S)}{\\Pr(W)}$$\n",
    "$Pr(S|W)$ is the probability that the email is a spam, knowing that the target word is in it. Namely, the probability that the email containing the target word is a spam.<br>\n",
    "$Pr(W|S)$ is the probability that the target word is in the email, knowing that the email is a spam. Namely, the probability that the target word appears in a spam.<br>\n",
    "$Pr(S)$ is the probability that the given email is a spam.<br>\n",
    "$Pr(W)$ is the probability that the word appears in any emails.<br>\n",
    "\n",
    "To futher break down $Pr(W)$, we can calculate it as:\n",
    "$$\\Pr(W)={\\Pr(W|S)\\Pr(S)}+{\\Pr(W|H)\\Pr(H)}$$\n",
    "Because the word appears either appears in a ham or spam, we can calculate $Pr(w)$ as the sum of the probability that the word appears in hams, and the probability that the word appears in spams.\n",
    "\n",
    "The probability that the word appears in spams can be calculated as $Pr(W|S)Pr(S)$. Namely, the probability that the probability that the target word appears in a spam multiplied by the probability that the given email is a spam.<br>\n",
    "\n",
    "The probability that the word appears in hams can be calculated as $Pr(W|H)Pr(H)$. Namely, the probability that the probability that the target word appears in a ham multiplied by the probability that the given email is a ham.\n",
    "\n",
    "To plug in the formula of $Pr(w)$ into the formula of Bayes' Theorem, we can the formula:\n",
    "$$\\Pr(S|W)=\\frac{\\Pr(W|S)\\Pr(S)}{\\Pr(W|S)\\Pr(S)+\\Pr(W|H)\\Pr(H)}$$\n",
    "\n",
    "Now, the question is what are $Pr(S)$ and $Pr(H)$? If we are taking more features into account, such as probability of the email from a certain email address is 80% a spam and 20% a ham, we can take the exact value into calculation. However, because we are only using Naive Bayes Classifier to analyze the body of emails, we have unbiased hypothesis on whether a email is spam or ham. Therefore, $\\Pr(S)=\\Pr(H)=0.5$.\n",
    "Since $Pr(S) = Pr(H)$, we can simplify the formula above as:\n",
    "$$\\Pr(S|W)=\\frac{\\Pr(W|S)}{\\Pr(W|S)+\\Pr(W|H)}$$\n",
    "### Spamicity and Spam Score\n",
    "Now we found a way to calculate the probability that the email containing the target word is a spam. In our context, $Pr(W|S)$ can be calculated as the number of spams containing the target word divided by the total number of spams. We can look up the word in \"spam_bow\" to obtain the number of spams containing the target word, and get the length of \"spams\" to obtain the total number of spams. \n",
    "\n",
    "On the other hand, $Pr(W|H)$ can be calculated as the number of hams containing the target word divided by the total number of hams. We can look up the word in \"ham_bow\" to obtain the number of hams containing the target word, and get the length of \"inbox\" to obtain the total number of hams. \n",
    "\n",
    "We also need to consider an edge case. What if the filter has never seen the target word before? Since the target word is not in both of the bag-of-words. $Pr(W|S)$ and $Pr(W|H)$ will be 0, resulting in the divisor of our formula, $Pr(W|S) + Pr(W|H)$ to be 0. To solve this problem, we will be make the filter be more lenient and let the word pass the filter with a spamicity of 0.\n",
    "\n",
    "After figuring out the way to calculate the spamicity of each word, the \"spam_score\" function will loop through each word of the email and calculate the spam score of email according to the spamicity of each word. \n",
    "* If a word's spamicity is from 0 to 0.5, then the word is safe and will not add any points to the spam score of the email. \n",
    "* If a word's spamicity is from 0.5 to 0.75, it will add 1 points to the spam score of the email. \n",
    "* If a word's spamicity is from 0.75 to 0.9, it will add 2 points to the spam score of the email. \n",
    "* If a word's spamicity is from 0.9 to 1, it will add 3 points to the spam score of the email.\n",
    "\n",
    "The last step is to receive a email. In the \"receive\" function, the filter will receive the email, calculate the spam score of that email and sort it to either \"inbox\" as a ham, or \"spams\" as a spam. This function will also further train the filter by adding the words of the email to the corresponding bag-of-words. Note: a certain word may appear multiple times in a email, but we are only adding it once a email, because the value of that word in the bag-of-words denotes the number of emails the word appears.\n",
    "## Training\n",
    "After constructing the 2 classes, we need to train the filter to let it work. For a real filter, we need a great amount of spams and hams to train it. But for demonstration purpose, I will only use 2 spams and 2 hams for training. The training spams will be subscription confirmation emails we hate to receive. Here is the text of one of the training spams.\n",
    "\n",
    "*Thank you for subscribing. To begin receiving the newsletter, you must first confirm your subscription.*\n",
    "\n",
    "Now, we will pass the training data in a filter with a threshold of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and testing data\n",
    "spam1 = Email('spam1_train','spam1.txt')\n",
    "spam2 = Email('spam2_train','spam2.txt')\n",
    "spam3 = Email('spam3_test','spam3.txt')\n",
    "ham1  = Email('ham1_train','ham1.txt')\n",
    "ham2  = Email('ham2_train','ham2.txt')\n",
    "ham3  = Email('ham3_test','ham3.txt')\n",
    "#creating the filter and set the threshold to 10\n",
    "spam_filter = Filter(10)\n",
    "#training\n",
    "spam_filter.train(spam1, True)\n",
    "spam_filter.train(spam2, True)\n",
    "spam_filter.train(ham1, False)\n",
    "spam_filter.train(ham2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the filter is trained, let us explore what are the bag-of-words of spams look like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thank': 1,\n",
       " 'subscrib': 1,\n",
       " 'to': 2,\n",
       " 'begin': 1,\n",
       " 'receiv': 1,\n",
       " 'newslett': 1,\n",
       " 'must': 1,\n",
       " 'first': 1,\n",
       " 'confirm': 1,\n",
       " 'subscript': 4,\n",
       " 'you': 2,\n",
       " 'purchas': 1,\n",
       " 'follow': 1,\n",
       " 'free': 3,\n",
       " 'trial': 3,\n",
       " 'charg': 1,\n",
       " 'after': 1,\n",
       " 'end': 1,\n",
       " 'renew': 1,\n",
       " 'unless': 1,\n",
       " 'cancel': 2,\n",
       " 'nov': 1,\n",
       " 'learn': 1,\n",
       " 'review': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_filter.spam_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 2 training spams are added to the \"spams\" of \"spamFilter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spams:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['spam1_train', 'spam2_train']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('spams:')\n",
    "[mail.get_id() for mail in spam_filter.spams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 training hams are also added to the \"inbox\" of \"spam_filter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hams:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ham1_train', 'ham2_train']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('hams:')\n",
    "[mail.get_id() for mail in spam_filter.inbox]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the spamicity of a word's stem. For example, let us try \"subscript\" and \"thank\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spamicity of \"subscript\" is 1.0\n",
      "the spamicity of \"thank\" is 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print('the spamicity of \"subscript\" is ' + str(spam_filter.word_spamicity('subscript')))\n",
    "print('the spamicity of \"thank\" is ' + str(spam_filter.word_spamicity('thank')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Subscript\" gets the spamicity of 1 because it appears twice in the 2 spams but not in any hams. \"Thank\" gets the spamicity of 0.5 because it appears once in the 2 spams and once in the 2 hams.\n",
    "We can see the spam scores of these 4 training emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score of spam1_train is 23\n",
      "the score of spam2_train is 70\n",
      "the score of ham1_train is 2\n",
      "the score of ham2_train is 1\n"
     ]
    }
   ],
   "source": [
    "print('the score of spam1_train is ' + str(spam_filter.spam_score(spam1)))\n",
    "print('the score of spam2_train is ' + str(spam_filter.spam_score(spam2)))\n",
    "print('the score of ham1_train is ' + str(spam_filter.spam_score(ham1)))\n",
    "print('the score of ham2_train is ' + str(spam_filter.spam_score(ham2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pass the testing data in the filter to check if the filter is well-trained.\n",
    "This is the text of the testing spam, another subscription confirmation email:\n",
    "\n",
    "*Please Confirm Subscription. Yes, subscribe me to this list. If you received this email by mistake, simply delete it. You won't be subscribed if you don't click the confirmation link above. For questions about this list, please contact:*\n",
    "\n",
    "This is the text of the testing ham, a email about COVID-19:\n",
    "\n",
    "*We understand that the recent news and uncertainty surrounding the COVID-19 situation may have caused you to re-think your travel plans and future travel options. Whether you have a trip booked or are planning upcoming travel, we will do whatever we can to support you. We are continually monitoring the situation, including travel restrictions and updates to travel policies that may impact you.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam3_test is a spam. Its Spam score is 15\n",
      "ham3_test is not a spam. Its Spam score is 0\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "spam_filter.receive(spam3)\n",
    "spam_filter.receive(ham3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter successfully filtered \"spam3_test\" as a spam and passed \"ham3_test\" as a ham.\n",
    "\n",
    "However, this filter is only for demonstration purpose of the application of simple text cleaning and Naive Bayes Classifier. In the real life, we need to consider more features other than contents, such as senders' addresses and subject. We need more complicated models, like decision trees, to build a spam filter like that in Gmail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
